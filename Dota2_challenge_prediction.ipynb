{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('features.csv', index_col='match_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-1. Explanation for absent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start_time                         0\n",
       "lobby_type                         0\n",
       "r1_hero                            0\n",
       "r1_level                           0\n",
       "r1_xp                              0\n",
       "r1_gold                            0\n",
       "r1_lh                              0\n",
       "r1_kills                           0\n",
       "r1_deaths                          0\n",
       "r1_items                           0\n",
       "r2_hero                            0\n",
       "r2_level                           0\n",
       "r2_xp                              0\n",
       "r2_gold                            0\n",
       "r2_lh                              0\n",
       "r2_kills                           0\n",
       "r2_deaths                          0\n",
       "r2_items                           0\n",
       "r3_hero                            0\n",
       "r3_level                           0\n",
       "r3_xp                              0\n",
       "r3_gold                            0\n",
       "r3_lh                              0\n",
       "r3_kills                           0\n",
       "r3_deaths                          0\n",
       "r3_items                           0\n",
       "r4_hero                            0\n",
       "r4_level                           0\n",
       "r4_xp                              0\n",
       "r4_gold                            0\n",
       "                               ...  \n",
       "d5_lh                              0\n",
       "d5_kills                           0\n",
       "d5_deaths                          0\n",
       "d5_items                           0\n",
       "first_blood_time               19553\n",
       "first_blood_team               19553\n",
       "first_blood_player1            19553\n",
       "first_blood_player2            43987\n",
       "radiant_bottle_time            15691\n",
       "radiant_courier_time             692\n",
       "radiant_flying_courier_time    27479\n",
       "radiant_tpscroll_count             0\n",
       "radiant_boots_count                0\n",
       "radiant_ward_observer_count        0\n",
       "radiant_ward_sentry_count          0\n",
       "radiant_first_ward_time         1836\n",
       "dire_bottle_time               16143\n",
       "dire_courier_time                676\n",
       "dire_flying_courier_time       26098\n",
       "dire_tpscroll_count                0\n",
       "dire_boots_count                   0\n",
       "dire_ward_observer_count           0\n",
       "dire_ward_sentry_count             0\n",
       "dire_first_ward_time            1826\n",
       "duration                           0\n",
       "radiant_win                        0\n",
       "tower_status_radiant               0\n",
       "tower_status_dire                  0\n",
       "barracks_status_radiant            0\n",
       "barracks_status_dire               0\n",
       "Length: 108, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.isnull(data).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__first_blood_time, first_blood_team, first_blood_player1, first_blood_player2__  \n",
    "These values are absent because there wasn't \"First Blood\" event within first 5 minutes of gameplay.  \n",
    "  \n",
    "__radiant_first_ward_time, dire_bottle_time, dire_courier_time, dire_flying_courier_time__  \n",
    "These values are absent because players did not acquired this items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-2. Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target variable is: __radiant_win__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data['radiant_win']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-3. GBC model training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training set\n",
    "data = data.fillna(0)\n",
    "X_train = data.drop(labels=['start_time', 'duration', 'radiant_win', 'tower_status_radiant',\n",
    "                    'tower_status_dire', 'barracks_status_radiant', 'barracks_status_dire'],\n",
    "                   axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 10; Score: 0.65, Time: 0:00:07.800433\n",
      "N: 20; Score: 0.68, Time: 0:00:11.602616\n",
      "N: 30; Score: 0.69, Time: 0:00:17.671740\n",
      "N: 40; Score: 0.69, Time: 0:00:18.645810\n",
      "N: 50; Score: 0.7, Time: 0:00:22.322764\n"
     ]
    }
   ],
   "source": [
    "for n in np.arange(10, 60, 10):\n",
    "    start_time = datetime.datetime.now()\n",
    "    #clf = GradientBoostingClassifier(n_estimators=n)\n",
    "    clf = GradientBoostingClassifier(n_estimators=n, max_depth=1, learning_rate=0.3)\n",
    "    score = cross_val_score(clf, X_train, y_train, cv=kf, scoring='roc_auc')\n",
    "    \n",
    "    print('N: {}; Score: {}, Time: {}'.format(n, round(score.mean(), 2), datetime.datetime.now() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation with __30 estimators__ _without optimisation_ takes __59 seconds__ on current hardware  \n",
    "ROC AUC score was __0.69__\n",
    "> N: 30; Score: 0.69, Time: 0:00:59.729096"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-4. Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 40+ estimators __without optimisation__ quality continue to grow slowly. But also it takes significantly more time for training:  \n",
    "> N: 10; Score: 0.66, Time: 0:00:22.314665  \n",
    "> N: 20; Score: 0.68, Time: 0:00:38.638311  \n",
    "> N: 30; Score: 0.69, Time: 0:00:59.729096  \n",
    "> N: 40; Score: 0.69, Time: 0:01:21.803030  \n",
    "> N: 50; Score: 0.7, Time: 0:01:31.827706  \n",
    "  \n",
    "To reduce learinig time we can decrease max_depth and increase learning rate. (max_depth=1, learning_rate=0.3):  \n",
    "> N: 50; Score: 0.7, Time: 0:00:22.322764\n",
    "\n",
    "__Optimal parameters:__ n_estimators=50, max_depth=1, learning_rate=0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-1. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/user/.local/lib/python2.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# normalize data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1e-05; Score: 0.7, Time: 0:00:02.599329\n",
      "C: 0.0001; Score: 0.71, Time: 0:00:04.681454\n",
      "C: 0.001; Score: 0.72, Time: 0:00:06.879551\n",
      "C: 0.01; Score: 0.72, Time: 0:00:10.063020\n",
      "C: 0.1; Score: 0.72, Time: 0:00:10.956006\n",
      "C: 1.0; Score: 0.72, Time: 0:00:11.570537\n",
      "C: 10.0; Score: 0.72, Time: 0:00:11.331998\n",
      "C: 100.0; Score: 0.72, Time: 0:00:11.262324\n"
     ]
    }
   ],
   "source": [
    "for c in np.power(10.0,np.arange(-5,3)):\n",
    "    start_time = datetime.datetime.now()\n",
    "    clf = LogisticRegression(C=c, penalty='l2')\n",
    "    score = cross_val_score(clf, X_train_scaled, y_train, cv=kf, scoring='roc_auc')\n",
    "    \n",
    "    print('C: {}; Score: {}, Time: {}'.format(c, round(score.mean(), 2), datetime.datetime.now() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression quality stops to grow after C==0.001. Best result is:\n",
    "> C: 0.001; Score: 0.72, Time: 0:00:07.986668  \n",
    "  \n",
    "So, this model has approximately the same uqality, but 3x faster cross validation speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-2. Logistic regression without categorial attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(labels=['lobby_type','r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero',\n",
    "                         'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'], axis=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python2.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/user/.local/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1e-05; Score: 0.7, Time: 0:00:02.624111\n",
      "C: 0.0001; Score: 0.71, Time: 0:00:03.983182\n",
      "C: 0.001; Score: 0.72, Time: 0:00:06.447332\n",
      "C: 0.01; Score: 0.72, Time: 0:00:09.481324\n",
      "C: 0.1; Score: 0.72, Time: 0:00:09.903293\n",
      "C: 1.0; Score: 0.72, Time: 0:00:09.920212\n",
      "C: 10.0; Score: 0.72, Time: 0:00:10.133123\n",
      "C: 100.0; Score: 0.72, Time: 0:00:10.459339\n"
     ]
    }
   ],
   "source": [
    "for c in np.power(10.0,np.arange(-5,3)):\n",
    "    start_time = datetime.datetime.now()\n",
    "    clf = LogisticRegression(C=c, penalty='l2')\n",
    "    score = cross_val_score(clf, X_train_scaled, y_train, cv=kf, scoring='roc_auc')\n",
    "    \n",
    "    print('C: {}; Score: {}, Time: {}'.format(c, round(score.mean(), 2), datetime.datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing of categorial attributes there is some improvement in cross validation time, but quality not changed:\n",
    "> C: 0.001; Score: 0.72, Time: 0:00:05.904471  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3. Heroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, (108,))\n"
     ]
    }
   ],
   "source": [
    "heroes = data[['r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero',\n",
    "              'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']].copy()\n",
    "unique_heroes = np.unique(heroes)\n",
    "print (unique_heroes.max(), unique_heroes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are __112__ unique IDs of heroes in this game, but in current dataset appears only __108__  \n",
    "Other 4 heroes can be very unpopular, or was blocked for selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-4. Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pick = np.zeros((data.shape[0], 112))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1 \n",
    "        X_pick[i, data.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "X_train_scaled = np.concatenate((X_pick, X_train_scaled),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1e-05; Score: 0.7, Time: 0:00:03.268058\n",
      "C: 0.0001; Score: 0.72, Time: 0:00:04.539747\n",
      "C: 0.001; Score: 0.75, Time: 0:00:11.135644\n",
      "C: 0.01; Score: 0.75, Time: 0:00:18.631219\n",
      "C: 0.1; Score: 0.75, Time: 0:00:22.087059\n",
      "C: 1.0; Score: 0.75, Time: 0:00:26.460977\n",
      "C: 10.0; Score: 0.75, Time: 0:00:26.161372\n",
      "C: 100.0; Score: 0.75, Time: 0:00:26.263226\n"
     ]
    }
   ],
   "source": [
    "for c in np.power(10.0,np.arange(-5,3)):\n",
    "    start_time = datetime.datetime.now()\n",
    "    clf = LogisticRegression(C=c, penalty='l2')\n",
    "    score = cross_val_score(clf, X_train_scaled, y_train, cv=kf, scoring='roc_auc')\n",
    "    \n",
    "    print('C: {}; Score: {}, Time: {}'.format(c, round(score.mean(), 2), datetime.datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage of \"Bag of words\" improved quality up to __0.75__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pandas.read_csv('features_test.csv', index_col='match_id')\n",
    "data_test = data_test.drop('start_time', axis=1)\n",
    "data_test = data_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pick = np.zeros((data_test.shape[0], 112))\n",
    "\n",
    "for i, match_id in enumerate(data_test.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data_test.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1 \n",
    "        X_pick[i, data_test.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "X_test = data_test.drop(labels=['lobby_type','r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero',\n",
    "                         'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'], axis=1)\n",
    "scaler = StandardScaler().fit(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled = np.concatenate((X_pick, X_test_scaled),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=1e-3, penalty='l2')\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "pred = clf.predict_proba(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 1.0\n"
     ]
    }
   ],
   "source": [
    "print (round(pred[:,1].min(), 2), round(pred[:,1].max()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min and max prediction values are: __0.01 1.0__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
